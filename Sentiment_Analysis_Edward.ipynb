{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_Analysis_Edward.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP7Ty1fONmv17EZzyCurzJd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edward2018211/sentiment-analysis-SOS/blob/master/Sentiment_Analysis_Edward.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1al0gyn83YM",
        "colab_type": "text"
      },
      "source": [
        "This notebook is a part of the News Sentiment Analysis project and contains snippets of code. Below is initial setup."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzXvdI628lwO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "befc7c12-5da5-41e6-aebf-c3fbe5f6eba3"
      },
      "source": [
        "# Download dependencies\n",
        "!pip install ImageScraper # https://pypi.org/project/ImageScraper/\n",
        "\n",
        "# Import libraries\n",
        "import tensorflow as tf\n",
        "import image_scraper as imagescraper"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ImageScraper in /usr/local/lib/python3.6/dist-packages (2.0.7)\n",
            "Requirement already satisfied: lxml>=3.2.3 in /usr/local/lib/python3.6/dist-packages (from ImageScraper) (4.2.6)\n",
            "Requirement already satisfied: SimplePool in /usr/local/lib/python3.6/dist-packages (from ImageScraper) (0.1)\n",
            "Requirement already satisfied: future>=0.14.3 in /usr/local/lib/python3.6/dist-packages (from ImageScraper) (0.16.0)\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from ImageScraper) (2.23.0)\n",
            "Requirement already satisfied: setproctitle>=1.1.8 in /usr/local/lib/python3.6/dist-packages (from ImageScraper) (1.1.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.1.0->ImageScraper) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.1.0->ImageScraper) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.1.0->ImageScraper) (2020.4.5.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.1.0->ImageScraper) (2.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_9Su4QI9UFr",
        "colab_type": "text"
      },
      "source": [
        "We will first scrape images from Google using a simple script for processing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbeWrZkA-FVU",
        "colab_type": "text"
      },
      "source": [
        "Next, we will manually label the images that are scraped to use as training data for our model in Tensorflow. An additional suggestion is that we could use data augmentation for more data, but we do need be aware of photos that wouldn't make sense to data augment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0_sayLC-WbK",
        "colab_type": "text"
      },
      "source": [
        "We will need to do some feature engineering for better prediction accuracy. We'll need multiple layers for our deep neural network and we'll probably want to work in increased stride length for a faster model that uses less memory. Probably dropout too to combat overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNNZJx7M-fIb",
        "colab_type": "text"
      },
      "source": [
        "Once the model is fine-tuned, it will be able to make predictions based on new images (data)."
      ]
    }
  ]
}